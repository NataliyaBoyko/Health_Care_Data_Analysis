{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae688d83-7c1f-4562-978d-c3a381d14bb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode_vertical.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074e2cbb-03e9-46a8-ae62-daee375aef6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Investigation of diabetes patients readmission among US hospitals**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d21ae10-5b07-4ee3-a77e-5accd97a2a2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lab 4 Data Analysis with Python\n\nEstimated time needed: **30** minutes\n\n## Objectives\n\n1. preprocess (normilize and transform categorical data) and create DataSet\n2. select features \n3. make classification of clients\n4. visualize decision tree of classification model  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e24cd0-4a69-4b28-b24a-42e2904fc05f",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Table of Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28d5d89-281d-4805-9f24-1892e958329f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li>Materials and Methods</li>\n        <li>Import Libraries</li>\n        <li>Load the Dataset</li>\n        <li>Data preparation\n            <ul>\n                <li>Data transformation</li>\n                <li>Encoding and Normalization</li>\n            </ul>\n        </li>\n        <li>Features selection\n             <ul>\n                <li>Chi-Squared Statistic</li>\n                <li>Mutual Information Statistic</li>\n                <li>Feature Importance</li>\n                <li>Correlation Matrix with Heatmap</li>\n            </ul>\n        </li>\n         <li>Tasks</li>\n        <li>Classification models\n            <ul>\n                <li>Train and Test DataSets creation</li>\n                <li>Extra Trees Classifier</li>\n                <li>Logistic regression </li>\n            </ul>\n        </li>\n        <li>Decision tree\n            <ul>\n                <li>Build model</li>\n                <li>Visualization of decision tree</li>\n            </ul>\n        </li>\n        <li>Conclusions</li>\n        <li>Authors</li>\n    </ol>\n</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41286de2-e2eb-4a71-8132-cdc7a1ddeac8",
      "metadata": {},
      "outputs": [],
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46382c4-769d-45cb-bc47-be85038175a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Materials and Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed6d1b0-ab72-46f4-9c4e-8fec22629986",
      "metadata": {},
      "outputs": [],
      "source": [
        "The data that we are going to use for this is a subset of an open source diabetes in US DataSet: https://www.kaggle.com/datasets/brandao/diabetes.\n\n> This dataset is public available for research.\nPlease include this citation if you plan to use this database:\nThe DataSet represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks.\n\nIt is important to know if a patient will be readmitted in some hospital. The reason is that you can change the treatment, in order to avoid a readmission.\n\nIn this lesson, we will try to give answers to a set of questions that may be relevant when analyzing diabetes data:\n\n1. What are the most useful Python libraries for classification analysis?\n2. How to transform category data?\n3. How to create DataSet?\n4. How to do features selection?\n5. How to make, fit and visualize classification model?\n\nIn addition, we will make the conclusions for the obtained results of our classification analysis to predict if a patient will be readmitted."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a515318d-393c-47a6-b6c0-530b7c3c6872",
      "metadata": {},
      "outputs": [],
      "source": [
        "[Scikit-learn](https://scikit-learn.org/stable/) (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7b4482-d7a0-44aa-91ed-7a379332326a",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ac9480-1f60-4997-9e14-5a2a05d051cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "Download data using a URL."
      ]
    },
    {
      "cell_type": "code",
      "id": "047c17b5-5233-464b-9ef1-0568780b6658",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1753615b-ebc0-4c31-a236-be484fe7ad74",
      "metadata": {},
      "outputs": [],
      "source": [
        "Alternative URL for the dataset downloading."
      ]
    },
    {
      "cell_type": "code",
      "id": "20c42604-c8b2-4b1d-ae5f-ddfdc890500a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VDA_Banking_L2/bank-additional.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f25fcca-0db2-4a3d-9e72-c2abda4aff64",
      "metadata": {},
      "outputs": [],
      "source": [
        "Unzipping to a folder. It is a good idea to apply the `-o` and `-q`  when unzipping to quiet the process and overwrite any existing folders.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "125c1365-8c02-4fda-8ade-acd155350a74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !unzip -o -q bank-additional.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3f3ed1-01a2-44bf-b0e7-2cbea62f5c83",
      "metadata": {},
      "outputs": [],
      "source": [
        "Import the libraries necessary to use in this lab. We can add some aliases to make the libraries easier to use in our code and set a default figure size for further plots. Ignore the warnings.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd7d5726-a567-4167-9b1c-8734a6edd0ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda install --yes scikit-learn==0.24.2\n!conda install --yes python-graphviz"
      ]
    },
    {
      "cell_type": "code",
      "id": "810220c9-82fc-45cb-9391-00ce5d18fa17",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (8, 6)\n# Data transformation\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n# Features Selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, mutual_info_classif\n# Classificators\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn import tree\n# warnings deactivate\nimport warnings\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0f7c03-fabb-4a75-b735-fb17387b9a0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3 .Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "649acacc-86e9-4069-96bb-3cce1fcfb175",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the same DataSet like in previous labs. Therefore next some steps will be the same"
      ]
    },
    {
      "cell_type": "code",
      "id": "6cec220b-e70b-47ca-a7f0-a6f83bd05455",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX027CEN/clean_df.csv', index_col=0)\ndf.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "id": "700ff3a7-9882-4088-9744-badc2d9799bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f8bdb6-7f86-4694-b542-f93d85d08f2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see DataSet consist of 56 columns. Target column is \"Readmitted\". Also DataSet consist 101745 rows. In previous labs we investigated these columns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "360028d6-cb5e-48f0-a014-6c902ca192a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details>\n<summary><b>Click to see attribute information</b></summary>\nInput features (column names):\n\n1. `Encounter Id` - Unique identifier of an encounter  (int64)\n2. `Patient Number` - Unique identifier of a patient (int64)\n3. `Race` - (categorical: `Caucasian` `AfricanAmerican` `Other` `Asian` `Hispanic`)\n4. `Gender` - (categorical: `Female` `Male` `Unknown/Invalid`)\n5. `Age` -  Grouped in 10-year intervals (categorical: `[0-10)` `[10-20)` `[20-30)` `[30-40)` `[40-50)` `[50-60)` `[60-70)` `[70-80)` `[80-90)` `[90-100)`)\n6. `Weight` -  Weight in pounds (categorical: `[75-100)` `[50-75)` `[0-25)` `[100-125)` `[25-50)` `[125-150)` `[175-200)` `[150-175)` `>200`)\n7. `Admission Type Id` - Integer identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available (int64)\n8. `Discharge Disposition Id` - Integer identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available (int64)\n9. `Admission Source Id` - Integer identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital (int64)\n10. `Time In Hospital` - Integer number of days between admission and discharge (int64)\n11. `Payer Code` - Integer identifier corresponding to 23 distinct values, for example, Blue Cross\\Blue Shield, Medicare, and self-pay (categorical)\n12. `Medical Specialty` - Integer identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family\\general practice, and surgeon (categorical)\n13. `Num Lab Procedures` - Number of lab tests performed during the encounter (float64)\n14. `Num Procedures` -  Number of procedures (other than lab tests) performed during the encounter (int64)\n15. `Num Medications` - Number of distinct generic names administered during the encounter (int64)\n16. `Number Outpatient` - Number of outpatient visits of the patient in the year preceding the encounter (int64)\n17. `Number Emergency` - Number of emergency visits of the patient in the year preceding the encounter (int64)\n18. `Number Inpatient` - Number of inpatient visits of the patient in the year preceding the encounter(int64)\n19. `Diagnosis1` - The primary diagnosis (coded as first three digits of ICD9) (categorical)\n20. `Diagnosis2` - Secondary diagnosis (coded as first three digits of ICD9) (categorical)\n21. `Diagnosis3` - Additional secondary diagnosis (coded as first three digits of ICD9) (categorical)\n22. `Number Diagnoses` - Number of diagnoses entered to the system (float64)\n23. `Max Glu Serum` - Indicates the range of the result or if the test was not taken. Values: `>200`, `>300`, `normal`, and `none` if not measured (categorical)\n24. `A1c Result` - Indicates the range of the result or if the test was not taken. Values: `>8` if the result was greater than 8%, `>7` if the result was greater than 7% but less than 8%, `normal` if the result was less than 7%, and “none” if not measured (categorical)\n25. `Metformin` - patient medications (categorical)\n26. `Repaglinide` - patient medications (categorical)\n27. `Nateglinide` - patient medications (categorical)\n28. `Chlorpropamide` - patient medications (categorical)\n29. `Glimepiride` - patient medications (categorical)\n30. `Acetohexamide` - patient medications (categorical)\n31. `Glipizide` - patient medications (categorical)\n32. `Glyburide` - patient medications (categorical)\n33. `Tolbutamide` - patient medications (categorical)\n34. `Pioglitazone` - patient medications (categorical)\n35. `Acarbose` - patient medications (categorical)\n36. `Miglitol` - patient medications (categorical)\n37. `Troglitazone` - patient medications (categorical)\n38. `Tolazamide` - patient medications (categorical)\n39. `Examide` - patient medications (categorical)\n40. `Citoglipton` - patient medications (categorical)\n41. `Insulin` - patient medications (categorical)\n42. `Glyburide-metformin` - patient medications (categorical)\n43. `Glipizide-metformin` - patient medications (categorical)\n44. `Glimepiride-pioglitazone` - patient medications (categorical)\n45. `Metformin-rosiglitazone` - patient medications (categorical)\n46. `Metformin-pioglitazone` - patient medications (categorical)\n47. `Diabetes Medication` -  Indicates if there was any diabetic medication prescribed. Values: `True` and `False` (bool)\n48. **`Readmitted` [Target Column]** - Days to inpatient readmission. Values: `<30` if the patient was readmitted in less than 30 days, `>30` if the patient was readmitted in more than 30 days, and `No` for no record of readmission (categorical)\n49. `ages-binned`(categorical)\n50. `change_yes` - columns created in previous labs (int64)\n51. `change_no` - columns created in previous labs (int64)\n52. `Increased` - columns created in previous labs (int64)\n53. `No` - columns created in previous labs (int64)\n54. `Steady` - columns created in previous labs (int64)\n55. `Decreased` - columns created in previous labs (int64)\n\n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28f700a-0ace-4132-b2df-fb9fd1240df6",
      "metadata": {},
      "outputs": [],
      "source": [
        "Our goal is create the classification model that can predict  if the client will subscribe a term deposit or no? To do this we must analize and prepare data for such type of model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d5c263f-cc89-425a-acce-2c680c6088f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0011dca9-0b53-4754-a2df-938beb91b419",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Data transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb2515d-31ad-47c3-9f5f-3c3e570986ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "First of all we should investigate how pandas recognized types of features"
      ]
    },
    {
      "cell_type": "code",
      "id": "72e64379-3384-4621-b0a5-a7a6a78e9805",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a16b05f-7e25-4090-982c-abb97afc2f8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see all categorical features was recogized like object. We must change thair type on \"categorical\". "
      ]
    },
    {
      "cell_type": "code",
      "id": "18389c7c-f337-4002-83f0-353bdc4781d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "col_cat = list(df.select_dtypes(include=['object']).columns)\ncol_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902364ae-69bf-44ad-8292-83c1a59fbc43",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's look at the dataset size."
      ]
    },
    {
      "cell_type": "code",
      "id": "f82fa023-cdbe-4816-8eab-c5aa0414369c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[:, col_cat] = df[col_cat].astype('category')\ndf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c239a1-9e5e-45f5-9f21-fdf22db8a9dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "To see the unical values of exact feature (column) we can use:"
      ]
    },
    {
      "cell_type": "code",
      "id": "1c2a9b6e-9fa0-4722-96fc-fd446f190954",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Race'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ae69be-8ae3-4737-98d5-0a0c2d5b2a1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "As was signed earlier the dataset contains 101388 objects (rows), for each of which 52 features are set (columns), including 1 target feature (Readmitted). 37 features, including target are categorical. These data type of values cannot use for classification. We must transform it to int or float.\nTo do this we can use **[LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)** and **[OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)**. These functions can encode categorical features as an integer array.\n\nFirs of all we separate DataSet on input and output(target) DataSets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d6e7d2-3ef5-49c4-b7c9-2e5280971c7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Excluding columns that do not affect target columns\nColumns that do not affect the result be can excluded.\nIn our case such columns are  - `Encounter Id`, `Patient Number` and `Payer Code`."
      ]
    },
    {
      "cell_type": "code",
      "id": "338547d7-6c97-4b37-aa40-03ccadbf65d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(['Encounter Id','Patient Number','Payer Code'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d442df2-83ba-46a6-9dab-0f8b754d361e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from X we have to remove target column (Readmitted).\nX = df.iloc[:,df.columns != 'Readmitted']\ny = df[\"Readmitted\"]\nprint(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0b61ea-6b4b-4137-980b-a0a065295bab",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Encoding and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f16c5f-879f-432d-b124-7ff108f706dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "Than create list of categorical fields and transform thair values to int arrays: (Replace ##YOUR CODE GOES HERE## with your Python code.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7825d6e7-8795-4de3-8824-aeae383e5bdc",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  1: </h1>\n\n<b>Сreate list of categorical fields and transform thair values to int arrays.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "62cec8fa-664f-454c-9f4f-cd425b55626a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a35c737-a16f-43e7-8f72-e9cb6a0b2de0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n\n```python\ncol_cat =df.iloc[:,df.columns != 'Readmitted'].select_dtypes(include=['category']).columns\n\noe = OrdinalEncoder()\noe.fit(X[col_cat])\nX_cat_enc = oe.transform(X[col_cat])\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "code",
      "id": "bd4817f7-3ecd-49ea-94c7-b3201e444b63",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_cat_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b5b0382-0505-4160-a176-21df5ecd3583",
      "metadata": {},
      "outputs": [],
      "source": [
        "Than we must transform arrays back into DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "id": "24d081af-776d-4b5d-9f73-11f372bfcaf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_cat_enc = pd.DataFrame(X_cat_enc)\nX_cat_enc.columns = col_cat\nX_cat_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d150bd0d-6835-43c2-9dc0-a5af4924cc16",
      "metadata": {},
      "outputs": [],
      "source": [
        "Numerical fields can have different scale and can consists negative values. These will lead to round mistakes and exeptions for some AI methods. To avoid it these features must be normalized.\n\nLet's create list of numerical fields and normilize it using by **[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a5516e-4d54-448e-a568-731474582731",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  2: </h1>\n\n<b>Create list of numerical, float and boolean fields and normilize it using by MinMaxScaler.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "d6bcb043-de0b-4907-a919-6899853f36cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87639382-d1c0-4da6-83ef-5b1c0875505f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n    \n```python\ncol_num = df.select_dtypes(include=['int64','float','boolean']).columns\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_num_enc = scaler.fit_transform(X[col_num])\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "code",
      "id": "d9261dc0-dae0-42f0-93d1-003bc5f9a3af",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_num_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c7baba-47b5-4ebe-a7c5-e8736efab723",
      "metadata": {},
      "outputs": [],
      "source": [
        "Like in previous case transform back obtained arrays into DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "id": "051363f4-e005-4e0f-94c7-112854f02fc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_num_enc = pd.DataFrame(X_num_enc)\nX_num_enc.columns = col_num\nX_num_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc3fbc53-ecca-476e-bb09-e93d3103bfdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "Then we should concatenate these DataFrames in one input DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b0badf6-25d1-42da-9e1a-94d03a5c1d6b",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  3: </h1>\n\n<b>Concatenate these DataFrames in one input DataFrame.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "d53344f4-1703-4244-b2a8-2f246e8ca11b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7903501c-555e-48b2-948b-36fd2e2829e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n\n```python  \nx_enc = pd.concat([X_cat_enc, X_num_enc], axis=1)\nx_enc\n```\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9572f9-a244-4c33-ab76-79c6332808b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "The same transformation we must do for target field"
      ]
    },
    {
      "cell_type": "code",
      "id": "bd292fb5-c4c1-4c50-ab1c-d289731743da",
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\nle.fit(y)\ny_enc = le.transform(y)\ny_enc = pd.Series(y_enc)\ny_enc.columns = y.name"
      ]
    },
    {
      "cell_type": "code",
      "id": "9dc82af9-c025-4542-b8d0-5855f04ad2ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "id": "c4560e44-2b4d-4a8f-b0c4-ebcdc01a0ec4",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81136782-5f69-4666-984b-430e564183e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see values '<30' was changed to 0, '>30' to 1 and 'NO' to 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b76bff2-30f4-4b65-9785-2916e8e81959",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Features selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1b79f7-f3bd-46df-8477-914c8fa931dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "As was signed before input fields consists 20 features. Of coure some of them are more significant for classification. \n\nThere are two popular feature selection techniques that can be used for categorical input data and a categorical (class) target variable.\n\nThey are:\n\n* Chi-Squared Statistic.\n* Mutual Information Statistic.\n\nLet’s take a closer look at each in turn.\n\nTo do this we can use **[SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7446309-63de-48d3-8efa-90cc9de4d6c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Chi-Squared Statistic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bee35fd-5f5a-404f-965e-0ff2bb570445",
      "metadata": {},
      "outputs": [],
      "source": [
        "Pearson’s chi-squared statistical hypothesis test is an example of a test for independence between categorical variables.\n\nYou can learn more about this statistical test in the tutorial:\n\n[A Gentle Introduction to the Chi-Squared Test for Machine Learning](https://machinelearningmastery.com/chi-squared-test-for-machine-learning/)\nThe results of this test can be used for feature selection, where those features that are independent of the target variable can be removed from the dataset.\n\nThe scikit-learn machine library provides an implementation of the chi-squared test in the **[chi2()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2)** function. This function can be used in a feature selection strategy, such as selecting the top k most relevant features (largest values) via the SelectKBest class.\n\nFor example, we can define the SelectKBest class to use the chi2() function and select all (or most significant) features, then transform the train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a908ec83-cee9-4640-9335-5d1572de18da",
      "metadata": {},
      "outputs": [],
      "source": [
        "Apply SelectKBest class to extract top 10 best features"
      ]
    },
    {
      "cell_type": "code",
      "id": "dade1a33-26bb-4ed1-ab24-b0986a1be1fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "bestfeatures = SelectKBest(score_func=chi2, k=5)\nfit = bestfeatures.fit(x_enc,y_enc)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392338a3-47d4-4373-ac03-9f868850a3b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "concat two dataframes for better visualization "
      ]
    },
    {
      "cell_type": "code",
      "id": "68867380-6ff6-465b-99f4-ede8c9c9428e",
      "metadata": {},
      "outputs": [],
      "source": [
        "featureScores = pd.concat([dfcolumns, dfscores],axis=1).dropna()\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(round(featureScores.nlargest(5,'Score'),2))  #print 5 best features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d11af9c6-082a-4996-9732-c8789685fbea",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Mutual Information Statistic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a36e89-7c06-486a-a570-5aa9867a85b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "Mutual information from the field of information theory is the application of information gain (typically used in the construction of decision trees) to feature selection.\n\nMutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n\n[You can learn more about mutual information in the following tutorial.](https://machinelearningmastery.com/information-gain-and-mutual-information)\n\nThe scikit-learn machine learning library provides an implementation of mutual information for feature selection via the **[mutual_info_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)** function.\n\nLike chi2(), it can be used in the SelectKBest feature selection strategy (and other strategies)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f60ed1-813d-485b-bfc2-b4d9db74d07e",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  4: </h1>\n\n<b>Concatenate these DataFrames in one input DataFrame.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "39d17bd5-4c48-49f8-af37-1532d0b067c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a815d7a1-b62e-462c-9019-7ce33305f1a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n\n```python\nbestfeatures = SelectKBest(score_func=mutual_info_classif, k=5)\nfit = bestfeatures.fit(x_enc,y_enc)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([dfcolumns, dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(round(featureScores.nlargest(5,'Score'),2))  #print 5 best features\n```\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccd59bb9-a208-48ce-ae97-39b514b75007",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see these 2 function select different significant features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7bbde3-3c4f-4ca3-b130-343715a82960",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "075a73ef-5c35-44fc-a848-f57e10cbded9",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can get the feature importance of each feature of your DataFrame by using the feature importance property of the exact classification model.\nFeature importance gives you a score for each feature of your data, the higher the score more important or relevant is the feature towards your output variable.\nFor example:\nFeature importance is an inbuilt class that comes with **[Tree Based Classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)**, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ca2770-c46a-4bde-9d48-602af5fabbbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's create and fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "id": "0fb09506-2572-4262-a456-b80c0480bf65",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ExtraTreesClassifier()\nmodel.fit(x_enc,y_enc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1556a247-3ec0-4864-bf81-a9c6c68eda97",
      "metadata": {},
      "outputs": [],
      "source": [
        "use inbuilt class feature_importances of tree based classifiers"
      ]
    },
    {
      "cell_type": "code",
      "id": "213b3b32-594f-4ac0-9bd0-39b0ce5da9e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ddc87e-9916-459c-b8d3-b08b54a61471",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's transform it into Series and plot graph of feature importances for better visualization"
      ]
    },
    {
      "cell_type": "code",
      "id": "ef4b9225-5132-4f9e-b378-9f039bf87d60",
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_importances = pd.Series(model.feature_importances_, index=x_enc.columns)\nfeat_importances.nlargest(5).plot(kind='barh')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7195943-7a8c-4f2d-a267-4baf263744a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can see that for Extra Tree Classifier impotance of features are different than in previous cases. It means that there are not exact rules for features selection. And their impotance strictly depedence on model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a5fb43-b260-4d96-8e18-2082e3baa031",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Correlation Matrix with Heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f0b2c8-4c8b-4744-b2c6-c83ae0b95c61",
      "metadata": {},
      "outputs": [],
      "source": [
        "Correlation states how the features are related to each other.\nCorrelation can be positive (increase in one value of feature increases the value of the other variable) or negative (increase in one value of feature decreases the value of the other variable)\nHeatmap makes it easy to identify which features are most related to the other variable, we will plot heatmap of correlated features using the seaborn library."
      ]
    },
    {
      "cell_type": "code",
      "id": "ef82387f-1278-4423-b46c-2b3793785660",
      "metadata": {},
      "outputs": [],
      "source": [
        "corrmat = x_enc.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\ng=sns.heatmap(x_enc[top_corr_features].corr(),annot=False,cmap=\"RdYlGn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1341307-5ab2-439b-965d-f06ff8026aa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can notice that \"Examide\" and \"Citoglipton\" columns have no correlation on our HeatMap. So let's examine these columns."
      ]
    },
    {
      "cell_type": "code",
      "id": "f7077dc7-ce34-4e5c-8473-ca0b92b8b239",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc[['Examide', 'Citoglipton']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108cc100-b933-4c7e-81ef-60800d72a8ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now examine each column closely."
      ]
    },
    {
      "cell_type": "code",
      "id": "63b7584f-18a3-44b9-8e9c-7026922f4ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc['Examide'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "id": "2eb78fd3-1bc5-4f65-9ad7-f655c02cb895",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc['Citoglipton'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d82898-1fca-4b97-888d-af4c95ba9a4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "As we can see, these rows have a constant value of 0.0. We can't find a correlation between constant values, and it will have zero impact on our model, so the best decision is to remove \"Examide\" and \"Citoglipton\" columns."
      ]
    },
    {
      "cell_type": "code",
      "id": "93b83ccb-cc03-42ed-8cd4-0cc520a9bf4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc = x_enc.iloc[:,~x_enc.columns.isin(['Examide', 'Citoglipton'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f21bf7-49f5-4211-8f1c-d06dcc209a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6.Tasks"
      ]
    },
    {
      "cell_type": "code",
      "id": "94034963-18b2-4131-89d5-e97e4749f135",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea87e407-a59f-45da-8fe7-43e0a1909745",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  5: </h1>\n\n<b>Create user function that will calculate accuracy of defined classificator model.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "f70f1089-c401-4c6e-8824-85ff9fa3b75c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_ac(x_enc, y_enc, clf):\n    # Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b78262-64f0-4c8f-8d3f-cf23f2c713d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n\n```python\n    model = clf()\n    model.fit(x_enc, y_enc)\n    yhat = model.predict(x_enc)\n    accuracy_train = accuracy_score(y_enc, yhat)\n    return accuracy_train\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd1c69d6-3ec9-4369-bfab-64e9fa43beb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy: %.2f' % (model_ac(x_enc, y_enc, model) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67ef1a89-8af4-4ea5-a54a-80cf11bd6973",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  6: </h1>\n\n<b>Create user function that will calculate features impotance of defined classificator model.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "b14463f4-0c1b-47b2-8069-4931aa4d776c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_imp(x_enc, y_enc, clf):\n    # Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dbc5181-af5d-4fee-8fd3-6793e32f2603",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n    \n```python\n    model = clf()\n    model.fit(x_enc, y_enc)\n    feat_importances = pd.Series(model.feature_importances_, index=x_enc.columns)\n    return feat_importances.sort_values(ascending=False)\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "code",
      "id": "de8fbb98-c174-4517-acec-69c83478e300",
      "metadata": {},
      "outputs": [],
      "source": [
        "imp = model_imp(x_enc, y_enc, model)\nprint(imp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6fb0b5d-08bf-4111-8e48-0737d330b016",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  7: </h1>\n\n<b>Build plot that show accuracy of defined model dependence on numbers of input features.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "14494335-bd4a-40c0-8a2b-d121a1d9d3ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f4c77e-8d2f-4431-afb8-8f4fe7ecff8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n    \n```python\n\ncol = []\nac = []\nfor c in imp.index:\n    col.append(c)\n    ac.append(model_ac(x_enc[col], y_enc, model))\n    print('Input fields: ', len(col), 'Accuracy: %.2f' % (ac[-1] * 100))\nac = pd.Series(ac)\nac.plot()\n```\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "286e8489-6fb6-4c7d-8dd9-9534c3936143",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Classification models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f6baa7-b8c3-4b04-b431-7acac4f18211",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a064084d-6134-48c7-9a87-25c43f6e38cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  8: </h1>\n\n<b>Build ExtraTreesClassifier model.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "6d010164-7a91-4c05-8393-cd113750ddd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb68a740-c02c-4b8e-9d3f-a3d21360ffc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n\n```python\nmodel = ExtraTreesClassifier()\nmodel.fit(x_enc, y_enc)\n```\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07f392ba-3947-47d2-8b36-f1e7d91af70e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Evaluate the model on data to obtain predictions"
      ]
    },
    {
      "cell_type": "code",
      "id": "b076b38e-489c-469c-afb8-f2aa0e590f2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = model.predict(x_enc)\nprint(yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d891c59-9e22-49c8-b004-199346b68c66",
      "metadata": {},
      "outputs": [],
      "source": [
        "Evaluate accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "id": "3386aed0-6697-4717-881e-8376507a2a58",
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_enc, yhat)\nprint('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "877684b3-3b14-41e7-825f-710054776345",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca36288-356f-445e-adc3-9eb8c0edec8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see Accuracy of this model is very good.\n\nThere are many different techniques for scoring features and selecting features based on scores; how do you know which one to use?\n\nA robust approach is to evaluate models using different feature selection methods (and numbers of features) and select the method that results in a model with the best performance.\n\n**[Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)** is a good model for testing feature selection methods as it can perform better if irrelevant features are removed from the model. We will use this model in absolutelly similar way like previous one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d7a40e-6898-4a15-acf3-9f1f2c2751bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  9: </h1>\n\n<b>Build LogisticRegression model.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "bdb66a34-25b2-4efa-9b9a-2ce78aeafb7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ee416dc-0b57-422e-9220-6214cf5cfb1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n    \n```python\ncol = imp.nlargest(5).index\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(x_enc[col], y_enc)\nyhat = model.predict(x_enc[col])\naccuracy = accuracy_score(y_enc, yhat)\nprint('Accuracy: %.2f' % (accuracy*100))\n```\n\n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb2109e-3340-43a1-87ed-bd9417f209dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see on this DataSet this method is less accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53311f55-ac88-426d-be16-0bcdf6cf9634",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619eba89-0088-4705-93b4-bdec20876a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d74c8c4-586b-4e43-8ca3-eaef1659bb7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "As shown, the previous methods have high for medical data accuracy. However, the biggest drawback is the inability to visualize or justify the decision."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff3c26e-f8b3-46df-bed3-8d4d2ef35d67",
      "metadata": {},
      "outputs": [],
      "source": [
        "Decision trees are a popular supervised learning method for a variety of reasons. Benefits of decision trees include that they can be used for both regression and classification, they don’t require feature scaling, and they are relatively easy to interpret as you can visualize decision trees. This is not only a powerful way to understand your model, but also to communicate how your model works. Consequently, it would help to know how to make a visualization based on your model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61516407-1a3e-4c9e-a3bd-77876ae2690d",
      "metadata": {},
      "outputs": [],
      "source": [
        "A **[Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)** is a supervised algorithm used in machine learning. It is using a binary tree graph (each node has two children) to assign for each data sample a target value. The target values are presented in the tree leaves. To reach to the leaf, the sample is propagated through nodes, starting at the root node. In each node a decision is made, to which descendant node it should go. A decision is made based on the selected sample’s feature. Decision Tree learning is a process of finding the optimal rules in each internal tree node according to the selected metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fe1751-5906-4358-a8e0-e771c1fcc8a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "This metod allows also to calculate features impotance.\nLet's calculate them. Choice best 10 of them. Refit the model and visualize decision tree.\n\nBy, using the graph above, select max_depth to find the value that best fits DecisionTreeClassifier().\ncorrect syntax : DecisionTreeClassifier(max_depth=value)"
      ]
    },
    {
      "cell_type": "code",
      "id": "187435a8-2cb4-4260-907c-43b4d407f9fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(imp.nlargest(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "961d227f-7a3d-431a-8fce-1e056dab5dc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  10: </h1>\n\n<b>Build a DecisionTreeClassifier model and fit it with the most important features from above.</b>\n\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "3942a2e7-beb3-42ba-a8d0-0949bd8df68f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f23567-875a-482b-b018-657618c6ef72",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary>\n    \n```python\nmodel = DecisionTreeClassifier()\nX_most_important = x_enc[col]\n\nmodel.fit(X_most_important, y_enc)\nyhat = model.predict(X_most_important)\naccuracy = accuracy_score(y_enc, yhat)\nprint('Accuracy: %.2f' % (accuracy * 100))\n```\n    \n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a44d350d-7375-4396-af6f-c63c27fe8094",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Visualization of decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254fe5f3-0c6e-4705-a172-7e7b9e80ef52",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's visualize decision tree.\nThere are some ways to do it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d221e7-afdd-4a5a-a7e4-8b6a0cf8a5b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### _Text visualization_"
      ]
    },
    {
      "cell_type": "code",
      "id": "31d6edd7-e636-4103-80ec-3141c43d8fb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_representation = tree.export_text(model)\nprint(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665444f6-600c-497a-b010-b5dbeceae659",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can save it into file:"
      ]
    },
    {
      "cell_type": "code",
      "id": "f281cfe6-0fd6-4941-a544-77a660dcff05",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"decistion_tree.log\", \"w\") as fout:\n    fout.write(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e57808-878a-47c6-8529-63a18f8218e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### _Plot tree_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9cf6a4-e21b-4c34-99fb-dad9ae0b4040",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can plot tree using by two different way:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a74bbaa-4ae6-4029-aa6d-e329705cd7ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "**[plot_tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html)** (slow render - this can take some time):"
      ]
    },
    {
      "cell_type": "code",
      "id": "c4f8b231-6f2e-44e3-b5d4-39744f0e7415",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(100,100))\n_ = tree.plot_tree(model,\n            max_depth = 7,\n            feature_names = col,\n            class_names = y.unique(),\n            filled = True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "05cd7d5a-3f63-4354-9651-28a9ee5f9853",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig.savefig('decision_tree.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ab8dde-1e15-4bcf-9e9f-5e32f62bec0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "Or you can use **[python-graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html)** library. This is more fast function"
      ]
    },
    {
      "cell_type": "code",
      "id": "612cef8a-fc6e-45e4-a591-1f54a99055dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import graphviz\ndot_data = tree.export_graphviz(model,\n               max_depth = 7,\n               feature_names = col,\n               class_names = y.unique(),\n                                filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc98430b-2ccc-43b0-9783-d15fa62c0940",
      "metadata": {},
      "outputs": [],
      "source": [
        "After creation you can draw graph"
      ]
    },
    {
      "cell_type": "code",
      "id": "9dbb0bde-c406-4227-93da-94cb8f1f2ded",
      "metadata": {},
      "outputs": [],
      "source": [
        "graph = graphviz.Source(dot_data, format=\"png\")\ngraph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437d69ea-3014-4ee8-9466-6f12e0627140",
      "metadata": {},
      "outputs": [],
      "source": [
        "And render it into file:"
      ]
    },
    {
      "cell_type": "code",
      "id": "ef4059bc-dad4-48c8-b5b6-58e24184dc4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.render(\"decision_tree_graphivz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f34ba1-47c7-4e6c-b2d8-cd30f9fad20c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's try out our model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d252f0b-345e-42ad-a076-eca1d7ac1cd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Select patient with index 1 and using build up diagram above try to predict will patient be readmitted or not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed20add1-d29d-47fc-95ce-aa36c9f6894d",
      "metadata": {},
      "outputs": [],
      "source": [
        "Num Medications <= 0.119(0.15) --> false | Diagnosis1 <= 95.5(454) --> false | Diagnosis3 <= 86.5(766) --> false | Diagnosis2 <= 78.5(78) --> true | Diagnosis2 <= 53.5(78) --> false | Num Lab Procedures <= 0.195(0.076) --> true | Num Medications <= 0.144(0.15) --> false ==> **result is <30 , in DataSet Readmitted value is NO. Prediction is wrong because tree diagram is not fully build and prediction is not as presistant as it have to.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f500111-4b6a-4b78-9ea6-48b3e24f55f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Now select patient with index 0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b28880-9952-4941-be2a-00690f83c6f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "Num Medications <= 0.119(0.2) --> false | Diagnosis1 <= 95.5(259) --> false | Diagnosis3 <= 86.5(256) --> false | Diagnosis2 <= 78.5(246) --> false | Num Medications <= 0.469(0.2) --> true | Diagnosis1 <= 338.5(259) --> true | Diagnosis1 <= 275.5(259) --> true ==> **the result is <30, which matches the value in the dataset. So we correctly predicted the patient's value.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ab3bc3-b3f8-4518-9a37-6c155bc79e24",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a47ea6c-d606-4231-9df3-6e3cb251a1c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "In this lab we learned to do preliminary data processing. In particular, change data types, normalize and process categorical data. It was shown how to make feature selection by different methods. Learned how to build training and test DataSets. Shows how to work with different classifiers. It was also shown how to visualize a decision tree.\nAs a result of lab it was shown how on the basis of a statistical database predict."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21324f76-f4ec-4ec3-9688-3c122f958da1",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 10. Author"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e5edbd7-a294-416d-bb36-0340c93b7a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "[Yaroslav Vyklyuk, prof., PhD., DrSc](http://vyklyuk.bukuniver.edu.ua/en/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "917d29d9-fbac-4d9f-965d-13a7dbcb7dee",
      "metadata": {},
      "outputs": [],
      "source": [
        " Copyright &copy; 2021 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/)."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}